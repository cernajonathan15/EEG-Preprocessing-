{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orthogonalization and Optimal State Number Computation\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import mne\n",
    "from mne_connectivity import symmetric_orth\n",
    "from hmmlearn import hmm\n",
    "from scipy.signal import hilbert, resample, butter, lfilter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from scipy.optimize import fminbound\n",
    "import time\n",
    "import cupy as cp\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "# Define input and output directories\n",
    "files_in = '../data/in/subjects/'\n",
    "files_out = '../data/out/subjects/'\n",
    "\n",
    "def downsample_with_filtering(data, original_fs, target_fs):\n",
    "    \"\"\"Downsamples data with an anti-aliasing filter.\"\"\"\n",
    "    nyq_rate = original_fs / 2.0\n",
    "    cutoff_freq = target_fs / 2.0\n",
    "    normalized_cutoff = cutoff_freq / nyq_rate\n",
    "    b, a = butter(4, normalized_cutoff, btype='low')\n",
    "    filtered_data = lfilter(b, a, data, axis=2)\n",
    "    \n",
    "    duration = data.shape[2] / original_fs\n",
    "    new_num_samples = int(duration * target_fs)\n",
    "    downsampled_data = resample(filtered_data, new_num_samples, axis=2)\n",
    "    \n",
    "    return downsampled_data\n",
    "\n",
    "def apply_orthogonalization(data):\n",
    "    \"\"\"Applies orthogonalization to the given data.\"\"\"\n",
    "    analytic_signal = hilbert(data, axis=2)\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "    Q, R = np.linalg.qr(amplitude_envelope.reshape(-1, amplitude_envelope.shape[-1]).T)\n",
    "    rank = np.linalg.matrix_rank(R)\n",
    "    if rank < amplitude_envelope.shape[-1]:\n",
    "        print(f\"Warning: Signals appear to be collinear.\")\n",
    "    orthogonalized_data = symmetric_orth(amplitude_envelope)\n",
    "    orthogonalized_data = orthogonalized_data.reshape(amplitude_envelope.shape)\n",
    "    return orthogonalized_data\n",
    "\n",
    "def process_participant(subject, mode, dir_in, dir_out):\n",
    "    label_time_courses_file = os.path.join(dir_out, f\"{subject}_label_time_courses.npy\")\n",
    "    \n",
    "    if os.path.exists(label_time_courses_file):\n",
    "        try:\n",
    "            label_time_courses = np.load(label_time_courses_file)\n",
    "            print(f\"Loaded data for {subject} in mode {mode}\")\n",
    "            \n",
    "            downsampled_label_time_courses = downsample_with_filtering(label_time_courses, 513, 250)\n",
    "            orthogonalized_data = apply_orthogonalization(downsampled_label_time_courses)\n",
    "            \n",
    "            output_file_path = os.path.join(dir_out, \"orth.npy\")\n",
    "            np.save(output_file_path, orthogonalized_data)\n",
    "            print(f\"File saved successfully for participant {subject}, mode {mode} at {output_file_path}\")\n",
    "            \n",
    "            return orthogonalized_data\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {subject} in {mode}: {e}\")\n",
    "    else:\n",
    "        print(f\"File not found: {label_time_courses_file}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def determine_optimal_states(orthogonalized_data, subject, mode, start_state=3):\n",
    "    feature_variances = np.var(orthogonalized_data, axis=0)\n",
    "    fraction_of_max_variance = 0.05\n",
    "    variance_floor = fraction_of_max_variance * np.max(feature_variances)\n",
    "\n",
    "    features = np.mean(orthogonalized_data, axis=2)\n",
    "    features = np.ma.masked_invalid(features).filled(0)\n",
    "\n",
    "    reshaped_data = orthogonalized_data.reshape(-1, 1)\n",
    "\n",
    "    pca = PCA(n_components=0.99)\n",
    "    pca_data = pca.fit_transform(reshaped_data)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    pca_data = scaler.fit_transform(pca_data)\n",
    "\n",
    "    participant_start_time = time.time()\n",
    "    \n",
    "    state_numbers = range(start_state, 17)\n",
    "\n",
    "    for n_states in state_numbers:\n",
    "        state_start_time = time.time()\n",
    "        print(f\"Processing state: {n_states} | Subject: {subject} | Mode: {mode}\")\n",
    "\n",
    "        pca_data_gpu = cp.asarray(pca_data)\n",
    "\n",
    "        model = hmm.GaussianHMM(n_components=n_states, n_iter=50, covariance_type='full', tol=1e-7, verbose=False, params='st', init_params='stmc')\n",
    "        model.fit(pca_data_gpu.get())\n",
    "\n",
    "        log_likelihood = model.score(pca_data_gpu.get())\n",
    "        n_params = n_states * (2 * pca_data_gpu.shape[1] - 1)\n",
    "        aic = 2 * n_params - 2 * log_likelihood\n",
    "        bic = np.log(pca_data_gpu.shape[0]) * n_params - 2 * log_likelihood\n",
    "\n",
    "        state_elapsed_time = (time.time() - state_start_time) / 60\n",
    "        print(f\"Time taken for state {n_states}: {state_elapsed_time:.2f} minutes\")\n",
    "\n",
    "        with open(f\"aic_bic_{subject}_{mode}.txt\", \"a\") as f:\n",
    "            f.write(f\"{n_states}\\t{aic}\\t{bic}\\n\")\n",
    "\n",
    "    # Find the optimal number of states\n",
    "    with open(f\"aic_bic_{subject}_{mode}.txt\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        state_numbers = []\n",
    "        aics = []\n",
    "        bics = []\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            state_numbers.append(int(parts[0]))\n",
    "            aics.append(float(parts[1]))\n",
    "            bics.append(float(parts[2]))\n",
    "\n",
    "        min_aic_index = np.argmin(aics)\n",
    "        min_bic_index = np.argmin(bics)\n",
    "        optimal_state_aic = state_numbers[min_aic_index]\n",
    "        optimal_state_bic = state_numbers[min_bic_index]\n",
    "        optimal_states = int((optimal_state_aic + optimal_state_bic) / 2)\n",
    "\n",
    "        with open(f\"aic_bic_{subject}_{mode}.txt\", \"a\") as f:\n",
    "            f.write(f\"\\nOptimal state (AIC): {optimal_state_aic}\\n\")\n",
    "            f.write(f\"Optimal state (BIC): {optimal_state_bic}\\n\")\n",
    "            f.write(f\"Optimal state (Average): {optimal_states}\\n\")\n",
    "\n",
    "    print(f\"Optimal number of states based on AIC/BIC: {optimal_states}\")\n",
    "    participant_elapsed_time = (time.time() - participant_start_time) / 60\n",
    "    print(f\"Total time taken for participant {subject} ({mode}): {participant_elapsed_time:.2f} minutes\")\n",
    "\n",
    "    return optimal_states\n",
    "\n",
    "def main():\n",
    "    # Get user input for starting point\n",
    "    start_subject = input(\"Enter the starting participant number (e.g., 401): \")\n",
    "    start_mode = input(\"Enter the starting condition (EC or EO): \")\n",
    "    start_state = int(input(\"Enter the starting state number (3 to 16): \"))\n",
    "\n",
    "    # Load subject list\n",
    "    with open(\"./names.txt\", \"r\") as names:\n",
    "        subject_list = names.read().split('\\n')\n",
    "\n",
    "    start_index = subject_list.index(start_subject)\n",
    "\n",
    "    # Main processing loop\n",
    "    for i in range(start_index, len(subject_list)):\n",
    "        subject = subject_list[i]\n",
    "        \n",
    "        if subject == start_subject:\n",
    "            modes = [\"EO\"] if start_mode == \"EO\" else [\"EC\", \"EO\"]\n",
    "        else:\n",
    "            modes = [\"EC\", \"EO\"]\n",
    "\n",
    "        for mode in modes:\n",
    "            dir_in = os.path.join(files_in, subject, mode)\n",
    "            dir_out = os.path.join(files_out, subject, mode)\n",
    "\n",
    "            # Ensure output directory exists\n",
    "            os.makedirs(dir_out, exist_ok=True)\n",
    "\n",
    "            # Process participant data\n",
    "            orthogonalized_data = process_participant(subject, mode, dir_in, dir_out)\n",
    "\n",
    "            if orthogonalized_data is not None:\n",
    "                # Determine optimal number of states\n",
    "                optimal_states = determine_optimal_states(orthogonalized_data, subject, mode, start_state)\n",
    "                print(f\"Optimal number of states for {subject} in {mode}: {optimal_states}\")\n",
    "\n",
    "        # Reset start_state for subsequent subjects\n",
    "        start_state = 3\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-hmm_env]",
   "language": "python",
   "name": "conda-env-anaconda3-hmm_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
